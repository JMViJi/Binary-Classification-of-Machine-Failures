{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data import\n",
    "\n",
    "FE = 0 # Feature Engineering (0 = No, 1 = Yes)\n",
    "\n",
    "FR = 0 # Feature Reduction (0 = No, 1 = Yes)\n",
    "\n",
    "OR = 0  # Original not included\n",
    "\n",
    "CAT = 0 # Categorical data (0 = No, 1 = Yes)\n",
    "\n",
    "def dataset(FE, FR, OR, CAT):\n",
    "    if CAT == 0:\n",
    "        if OR == 0:\n",
    "            if FR == 0:\n",
    "                if FE == 0:\n",
    "                    X_train = pd.read_csv('data/X_train.csv')\n",
    "                    X_test = pd.read_csv('data/X_test.csv') # Test data\n",
    "                else:\n",
    "                    X_train = pd.read_csv('data/X_train_FE.csv')\n",
    "                    X_test = pd.read_csv('data/X_test_FE.csv') # Test data\n",
    "            else:\n",
    "                X_train = pd.read_csv('data/X_train_FR.csv')\n",
    "                X_test = pd.read_csv('data/X_test_FR.csv') # Test data\n",
    "        else:\n",
    "            if FE == 0:\n",
    "                X_train = pd.read_csv('data/X_total.csv')\n",
    "                X_test = pd.read_csv('data/X_test.csv') # Test data\n",
    "            else:\n",
    "                X_train = pd.read_csv('data/X_total_FE.csv')\n",
    "                X_test = pd.read_csv('data/X_test_FE.csv')\n",
    "    else:\n",
    "        X_train = pd.read_csv('data/X_train_CAT.csv')\n",
    "        X_test = pd.read_csv('data/X_test_CAT.csv') # Test data\n",
    "    \n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def ROC_AUC(model, X_train, y_train, n_splits=5, n_repeats=3):\n",
    "    \n",
    "    # Initialize the Repeated Stratified K Fold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    # Create an empty list to store the Out-of-Fold (OOF) predictions\n",
    "    oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "    # Loop through each split\n",
    "    for train_index, valid_index in rskf.split(X_train, y_train):\n",
    "    \n",
    "        # Split the data\n",
    "        X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "        # Make predictions and add them to the OOF predictions\n",
    "        oof_preds[valid_index] = model.predict_proba(X_valid_fold)[:,1]\n",
    "\n",
    "    # Calculate the overall AUC\n",
    "    auc = roc_auc_score(y_train, oof_preds)\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training datasets performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_LGBM = {'colsample_bytree': 0.1923023355270077,\n",
    "         'learning_rate': 0.03574583615481279,\n",
    "         'max_depth': 16, \n",
    "         'min_child_samples': 89, \n",
    "         'n_estimators': 260, \n",
    "         'num_leaves': 68, \n",
    "         'reg_alpha': 0.30028296727692755, \n",
    "         'reg_lambda': 0.6125642241926401, \n",
    "         'subsample': 0.7293703101825368\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_XGB =  {'max_depth': 13, \n",
    "         'learning_rate': 0.012308520402322306, \n",
    "         'colsample_bytree': 0.15564433647290904, \n",
    "         'subsample': 0.9392376085401448, \n",
    "         'n_estimators': 494, \n",
    "         'min_child_weight': 1, \n",
    "         'reg_alpha': 0.26760253520809857, \n",
    "         'reg_lambda': 0.24616802866656362} # best value: 0.9743947392021206."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Cat_Opt_AllCat = {'iterations': 249, \n",
    "                       'depth': 6, \n",
    "                       'learning_rate': 0.1555748471212781, \n",
    "                       'random_strength': 58, \n",
    "                       'bagging_temperature': 87.47376677399185, \n",
    "                       'od_type': 'IncToDec', \n",
    "                       'od_wait': 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best =  {'colsample_bytree': 0.19297355677628159, \n",
    "          'learning_rate': 0.020755882048032786, \n",
    "          'max_depth': 9, \n",
    "          'min_child_samples': 41, \n",
    "          'n_estimators': 320, \n",
    "          'num_leaves': 100, \n",
    "          'reg_alpha': 0.39149507035237485, \n",
    "          'reg_lambda': 0.43245778149146746, \n",
    "          'subsample': 0.5188437264047947} # best loss: -0.973283159101125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_sets = {'Normal dataset': [0, 0, 0, 0], 'Dataset With FE': [1, 0, 0, 0], 'Dataset With FE and FR': [1, 1, 0, 0], 'Dataset Ori + train no FE': [0, 0, 1, 0], 'Dataset Ori + train with FE': [1, 0, 1, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136429, 14)\n",
      "Model:  Normal dataset    AUC:  0.9706861467455258\n",
      "(136429, 24)\n",
      "Model:  Dataset With FE    AUC:  0.9663308554698875\n",
      "(136429, 21)\n",
      "Model:  Dataset With FE and FR    AUC:  0.966638698897308\n",
      "(146429, 14)\n",
      "Model:  Dataset Ori + train no FE    AUC:  0.9752747857937709\n",
      "(146429, 24)\n",
      "Model:  Dataset Ori + train with FE    AUC:  0.9718414288710988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define the model with the best parameters\n",
    "model_LGBM = lgb.LGBMClassifier(**Best)\n",
    "\n",
    "Scores = {}\n",
    "\n",
    "for name, model in Train_sets.items():\n",
    "\n",
    "    X_train, X_test  = dataset(model[0], model[1], model[2], model[3])\n",
    "    y_train = X_train['Machine_failure']\n",
    "    X_train = X_train.drop(['Machine_failure'], axis=1)\n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Initialize the Repeated Stratified K Fold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=42)\n",
    "\n",
    "    # Create an empty list to store the Out-of-Fold (OOF) predictions\n",
    "    oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "    # Loop through each split\n",
    "    for train_index, valid_index in rskf.split(X_train, y_train):\n",
    "        \n",
    "        # Split the data\n",
    "        X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model_LGBM.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Make predictions and add them to the OOF predictions\n",
    "        oof_preds[valid_index] = model_LGBM.predict_proba(X_valid_fold)[:,1]\n",
    "\n",
    "    # Calculate the overall AUC\n",
    "    auc = roc_auc_score(y_train, oof_preds)\n",
    "\n",
    "    print(\"Model: \", name, \"   AUC: \", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(136429, 14)\n",
    "Model:  Normal dataset    AUC:  0.9706861467455258\n",
    "(136429, 22)\n",
    "Model:  Dataset With FE    AUC:  0.9672851967906262\n",
    "(136429, 19)\n",
    "Model:  Dataset With FE and FR    AUC:  0.9653824357485317\n",
    "(146429, 14)\n",
    "Model:  Dataset Ori + train no FE    AUC:  0.9752747857937709\n",
    "(146429, 22)\n",
    "Model:  Dataset Ori + train with FE    AUC:  0.9726090433142951"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test  = dataset(0, 0, 1, 0)\n",
    "y_train = X_train['Machine_failure']\n",
    "X_train = X_train.drop(['Machine_failure'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CAT, X_test_CAT = dataset(0,0,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Product_ID', 'Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CAT[cat_columns] = X_train_CAT[cat_columns].astype('category')\n",
    "X_test_CAT[cat_columns] = X_test_CAT[cat_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Air_temperature_K</th>\n",
       "      <th>Process_temperature_K</th>\n",
       "      <th>Rotational_speed_rpm</th>\n",
       "      <th>Torque_Nm</th>\n",
       "      <th>Tool_wear_min</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>Type_H</th>\n",
       "      <th>Type_L</th>\n",
       "      <th>Type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50096</td>\n",
       "      <td>300.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1596</td>\n",
       "      <td>36.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20343</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1759</td>\n",
       "      <td>29.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49454</td>\n",
       "      <td>299.3</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1805</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53355</td>\n",
       "      <td>301.0</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1524</td>\n",
       "      <td>44.3</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24050</td>\n",
       "      <td>298.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  Air_temperature_K  Process_temperature_K  Rotational_speed_rpm  \\\n",
       "0       50096              300.6                  309.6                  1596   \n",
       "1       20343              302.6                  312.1                  1759   \n",
       "2       49454              299.3                  308.5                  1805   \n",
       "3       53355              301.0                  310.9                  1524   \n",
       "4       24050              298.0                  309.0                  1641   \n",
       "\n",
       "   Torque_Nm  Tool_wear_min  TWF  HDF  PWF  OSF  RNF  Type_H  Type_L  Type_M  \n",
       "0       36.1            140    0    0    0    0    0       0       1       0  \n",
       "1       29.1            200    0    0    0    0    0       0       0       1  \n",
       "2       26.5             25    0    0    0    0    0       0       1       0  \n",
       "3       44.3            197    0    0    0    0    0       0       1       0  \n",
       "4       35.4             34    0    0    0    0    0       0       0       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146429 entries, 0 to 146428\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count   Dtype   \n",
      "---  ------                 --------------   -----   \n",
      " 0   Product_ID             146429 non-null  category\n",
      " 1   Type                   146429 non-null  category\n",
      " 2   Air_temperature_K      146429 non-null  float64 \n",
      " 3   Process_temperature_K  146429 non-null  float64 \n",
      " 4   Rotational_speed_rpm   146429 non-null  int64   \n",
      " 5   Torque_Nm              146429 non-null  float64 \n",
      " 6   Tool_wear_min          146429 non-null  int64   \n",
      " 7   TWF                    146429 non-null  int64   \n",
      " 8   HDF                    146429 non-null  int64   \n",
      " 9   PWF                    146429 non-null  int64   \n",
      " 10  OSF                    146429 non-null  int64   \n",
      " 11  RNF                    146429 non-null  int64   \n",
      "dtypes: category(2), float64(3), int64(7)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [13:11<00:00, 15.83s/trial, best loss: -0.973283159101125] \n",
      "Best:  {'colsample_bytree': 0.19297355677628159, 'learning_rate': 0.020755882048032786, 'max_depth': 9.0, 'min_child_samples': 41.0, 'n_estimators': 320.0, 'num_leaves': 100.0, 'reg_alpha': 0.39149507035237485, 'reg_lambda': 0.43245778149146746, 'subsample': 0.5188437264047947}\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import lightgbm as lgb\n",
    "# hp \n",
    "from hyperopt import hp, tpe, STATUS_OK, Trials, fmin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "space ={\n",
    "    'max_depth': hp.quniform('max_depth', 6, 18, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.01, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.4, 1.0),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 400, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 100, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.15, 0.5),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.3, 1.0)\n",
    "}\n",
    "\n",
    "def objective(space):\n",
    "    model_LGBM = lgb.LGBMClassifier(max_depth = int(space['max_depth']),\n",
    "                             learning_rate = space['learning_rate'],\n",
    "                             num_leaves = int(space['num_leaves']),\n",
    "                             n_estimators = int(space['n_estimators']),\n",
    "                             colsample_bytree = space['colsample_bytree'],\n",
    "                             subsample = space['subsample'],\n",
    "                             is_unbalance = True,\n",
    "                             min_child_samples = int(space['min_child_samples']),\n",
    "                             reg_alpha = space['reg_alpha'],\n",
    "                             reg_lambda = space['reg_lambda'])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    y_pred_proba = cross_val_predict(model_LGBM, X_train, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "    auc = roc_auc_score(y_train, y_pred_proba)\n",
    "    return {'loss': -auc, 'status': STATUS_OK}\n",
    "\n",
    "# Run the algorithm\n",
    "trials = Trials()\n",
    "best_LGBM = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best_LGBM)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_LGBM =  {'colsample_bytree': 0.19297355677628159, \n",
    "          'learning_rate': 0.020755882048032786, \n",
    "          'max_depth': 9, \n",
    "          'min_child_samples': 41, \n",
    "          'n_estimators': 320, \n",
    "          'num_leaves': 100, \n",
    "          'reg_alpha': 0.39149507035237485, \n",
    "          'reg_lambda': 0.43245778149146746, \n",
    "          'subsample': 0.5188437264047947} # best loss: -0.973283159101125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LGBM = lgb.LGBMClassifier(**Best_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC LGBM:  0.9762130741832492\n"
     ]
    }
   ],
   "source": [
    "AUC_LGBM = ROC_AUC(model_LGBM, X_train, y_train)\n",
    "print(\"AUC LGBM: \", AUC_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.19297355677628159,\n",
       "               learning_rate=0.020755882048032786, max_depth=9,\n",
       "               min_child_samples=41, n_estimators=320, num_leaves=100,\n",
       "               reg_alpha=0.39149507035237485, reg_lambda=0.43245778149146746,\n",
       "               subsample=0.5188437264047947)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.19297355677628159,\n",
       "               learning_rate=0.020755882048032786, max_depth=9,\n",
       "               min_child_samples=41, n_estimators=320, num_leaves=100,\n",
       "               reg_alpha=0.39149507035237485, reg_lambda=0.43245778149146746,\n",
       "               subsample=0.5188437264047947)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.19297355677628159,\n",
       "               learning_rate=0.020755882048032786, max_depth=9,\n",
       "               min_child_samples=41, n_estimators=320, num_leaves=100,\n",
       "               reg_alpha=0.39149507035237485, reg_lambda=0.43245778149146746,\n",
       "               subsample=0.5188437264047947)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LGBM.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-20 18:43:02,580]\u001b[0m A new study created in memory with name: no-name-5718bf0b-b7b3-43c1-91d9-2445417e6fd4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-20 18:43:15,158]\u001b[0m Trial 0 finished with value: 0.9713728349806623 and parameters: {'max_depth': 9, 'learning_rate': 0.029179412645366845, 'colsample_bytree': 0.14179228442089745, 'subsample': 0.8725851015059102, 'n_estimators': 544, 'min_child_weight': 8, 'reg_alpha': 0.35704646398741113, 'reg_lambda': 0.4697658245581723, 'gamma': 0.05976736552903123, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.9713728349806623.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:43:27,776]\u001b[0m Trial 1 finished with value: 0.9715950378016317 and parameters: {'max_depth': 16, 'learning_rate': 0.1260985472345255, 'colsample_bytree': 0.10081084207759922, 'subsample': 0.8056571289897766, 'n_estimators': 381, 'min_child_weight': 9, 'reg_alpha': 0.0023665560833429937, 'reg_lambda': 0.3483418922540138, 'gamma': 0.08531269992877895, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.9715950378016317.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:43:34,140]\u001b[0m Trial 2 finished with value: 0.9634858401982118 and parameters: {'max_depth': 17, 'learning_rate': 0.0010267526675229418, 'colsample_bytree': 0.12929811518214004, 'subsample': 0.8714037839214553, 'n_estimators': 357, 'min_child_weight': 5, 'reg_alpha': 0.2663650384000579, 'reg_lambda': 0.4580672504505043, 'gamma': 0.07456625011684516, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 0.9715950378016317.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:43:45,872]\u001b[0m Trial 3 finished with value: 0.9712183112086143 and parameters: {'max_depth': 6, 'learning_rate': 0.10450594050054367, 'colsample_bytree': 0.1520818751333109, 'subsample': 0.8272179116990617, 'n_estimators': 343, 'min_child_weight': 10, 'reg_alpha': 0.38304769092856045, 'reg_lambda': 0.2899752802830073, 'gamma': 0.015375646588224177, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 0.9715950378016317.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:43:59,820]\u001b[0m Trial 4 finished with value: 0.9728393149371801 and parameters: {'max_depth': 9, 'learning_rate': 0.05307335945807161, 'colsample_bytree': 0.2675694822615246, 'subsample': 0.8059246917330821, 'n_estimators': 419, 'min_child_weight': 4, 'reg_alpha': 0.4529291783902772, 'reg_lambda': 0.4179576497228971, 'gamma': 0.05539132718753163, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:44:05,202]\u001b[0m Trial 5 finished with value: 0.9643785287530116 and parameters: {'max_depth': 5, 'learning_rate': 1.3412055608871718e-05, 'colsample_bytree': 0.17081842930860933, 'subsample': 0.9527037453343385, 'n_estimators': 277, 'min_child_weight': 4, 'reg_alpha': 0.2603982891418386, 'reg_lambda': 0.29418148469952793, 'gamma': 0.024235261451547408, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:44:14,094]\u001b[0m Trial 6 finished with value: 0.9636698331846647 and parameters: {'max_depth': 17, 'learning_rate': 0.000664306702151198, 'colsample_bytree': 0.13254678189172897, 'subsample': 0.9966700028172462, 'n_estimators': 503, 'min_child_weight': 1, 'reg_alpha': 0.35702865170104703, 'reg_lambda': 0.6145969895585178, 'gamma': 0.04057877511828566, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:44:44,505]\u001b[0m Trial 7 finished with value: 0.9723019916708289 and parameters: {'max_depth': 10, 'learning_rate': 0.011116020700922255, 'colsample_bytree': 0.216159815334301, 'subsample': 0.8184974978179169, 'n_estimators': 502, 'min_child_weight': 10, 'reg_alpha': 0.14938256601158706, 'reg_lambda': 0.37102027722318087, 'gamma': 0.04037985892826438, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:44:55,224]\u001b[0m Trial 8 finished with value: 0.9685090877056951 and parameters: {'max_depth': 15, 'learning_rate': 1.9040328839302824e-05, 'colsample_bytree': 0.10881414362571551, 'subsample': 0.9523321111451734, 'n_estimators': 211, 'min_child_weight': 3, 'reg_alpha': 0.017950682913181183, 'reg_lambda': 0.00016908115453504848, 'gamma': 0.053430852374467146, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:45:04,867]\u001b[0m Trial 9 finished with value: 0.9640925800225002 and parameters: {'max_depth': 18, 'learning_rate': 0.003303983466384037, 'colsample_bytree': 0.12525521413382765, 'subsample': 0.8027885252066289, 'n_estimators': 417, 'min_child_weight': 3, 'reg_alpha': 0.21762454520253618, 'reg_lambda': 0.3465526217845186, 'gamma': 0.0313322247052453, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:45:15,415]\u001b[0m Trial 10 finished with value: 0.963732168415665 and parameters: {'max_depth': 13, 'learning_rate': 0.000123133671292782, 'colsample_bytree': 0.2849355625018594, 'subsample': 0.8496635563769168, 'n_estimators': 447, 'min_child_weight': 7, 'reg_alpha': 0.49088875750391775, 'reg_lambda': 0.8349471725778594, 'gamma': 0.0005216824280078608, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:45:33,603]\u001b[0m Trial 11 finished with value: 0.9727546393069 and parameters: {'max_depth': 9, 'learning_rate': 0.00995495801540133, 'colsample_bytree': 0.24601624545328216, 'subsample': 0.8330262956634586, 'n_estimators': 568, 'min_child_weight': 6, 'reg_alpha': 0.1359988818741108, 'reg_lambda': 0.634826355698176, 'gamma': 0.04991285652640641, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:45:50,564]\u001b[0m Trial 12 finished with value: 0.9721032144939181 and parameters: {'max_depth': 8, 'learning_rate': 0.01153383415649166, 'colsample_bytree': 0.2505645405255227, 'subsample': 0.8441507723606949, 'n_estimators': 582, 'min_child_weight': 6, 'reg_alpha': 0.4808796371249991, 'reg_lambda': 0.6611334130093012, 'gamma': 0.06423512014855022, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:46:05,750]\u001b[0m Trial 13 finished with value: 0.9673773938914558 and parameters: {'max_depth': 13, 'learning_rate': 0.004860888669902176, 'colsample_bytree': 0.2872368644960212, 'subsample': 0.8390918082953063, 'n_estimators': 469, 'min_child_weight': 6, 'reg_alpha': 0.11322167473616346, 'reg_lambda': 0.9585206725487085, 'gamma': 0.09853891606634343, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 0.9728393149371801.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:46:22,979]\u001b[0m Trial 14 finished with value: 0.973112314756049 and parameters: {'max_depth': 7, 'learning_rate': 0.04228930303815941, 'colsample_bytree': 0.24625872616107747, 'subsample': 0.8016264106225779, 'n_estimators': 596, 'min_child_weight': 1, 'reg_alpha': 0.14213732005709406, 'reg_lambda': 0.6415045577399465, 'gamma': 0.04883079306674938, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:46:30,270]\u001b[0m Trial 15 finished with value: 0.9639844061191669 and parameters: {'max_depth': 7, 'learning_rate': 1.1471732789882753e-06, 'colsample_bytree': 0.2556197041901056, 'subsample': 0.8001435341779551, 'n_estimators': 307, 'min_child_weight': 1, 'reg_alpha': 0.43662665991719696, 'reg_lambda': 0.7972153773627295, 'gamma': 0.06611452934278257, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:46:40,432]\u001b[0m Trial 16 finished with value: 0.9723306954873712 and parameters: {'max_depth': 4, 'learning_rate': 0.05343973821431157, 'colsample_bytree': 0.20743062454759284, 'subsample': 0.864029531357976, 'n_estimators': 522, 'min_child_weight': 2, 'reg_alpha': 0.3183154348552893, 'reg_lambda': 0.5576477356481758, 'gamma': 0.047391854013396836, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:47:05,336]\u001b[0m Trial 17 finished with value: 0.9712789452450963 and parameters: {'max_depth': 12, 'learning_rate': 0.038990284700607794, 'colsample_bytree': 0.29667741529744757, 'subsample': 0.8891834285786744, 'n_estimators': 595, 'min_child_weight': 4, 'reg_alpha': 0.4308911077439813, 'reg_lambda': 0.7481435259589996, 'gamma': 0.07197293824096643, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:47:13,979]\u001b[0m Trial 18 finished with value: 0.9698099721586808 and parameters: {'max_depth': 11, 'learning_rate': 0.14974946478471862, 'colsample_bytree': 0.22772677315490134, 'subsample': 0.8223934772567676, 'n_estimators': 201, 'min_child_weight': 2, 'reg_alpha': 0.21282922926166337, 'reg_lambda': 0.5094836629955888, 'gamma': 0.05704652453738569, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:47:23,223]\u001b[0m Trial 19 finished with value: 0.9648297629171183 and parameters: {'max_depth': 7, 'learning_rate': 0.0021127829970315802, 'colsample_bytree': 0.18896313385219027, 'subsample': 0.8501941635406685, 'n_estimators': 433, 'min_child_weight': 4, 'reg_alpha': 0.422414728071521, 'reg_lambda': 0.9943592303545368, 'gamma': 0.04813457540955522, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:47:30,662]\u001b[0m Trial 20 finished with value: 0.9707258489165964 and parameters: {'max_depth': 6, 'learning_rate': 0.024824088832628245, 'colsample_bytree': 0.259014362378584, 'subsample': 0.8171783938782247, 'n_estimators': 273, 'min_child_weight': 2, 'reg_alpha': 0.3110009464489082, 'reg_lambda': 0.7225562366401439, 'gamma': 0.03699512239657327, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.973112314756049.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:47:49,620]\u001b[0m Trial 21 finished with value: 0.9732405621960152 and parameters: {'max_depth': 9, 'learning_rate': 0.013203808862093077, 'colsample_bytree': 0.23643991733563352, 'subsample': 0.8290520142777729, 'n_estimators': 569, 'min_child_weight': 7, 'reg_alpha': 0.13935633133623226, 'reg_lambda': 0.596713924806455, 'gamma': 0.05686398633713836, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9732405621960152.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:48:08,193]\u001b[0m Trial 22 finished with value: 0.9734609492921291 and parameters: {'max_depth': 10, 'learning_rate': 0.028429275105407246, 'colsample_bytree': 0.2703167339225339, 'subsample': 0.8160938171139327, 'n_estimators': 547, 'min_child_weight': 8, 'reg_alpha': 0.08681940766766832, 'reg_lambda': 0.5888775786208947, 'gamma': 0.05401227761787685, 'grow_policy': 'depthwise'}. Best is trial 22 with value: 0.9734609492921291.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:48:28,770]\u001b[0m Trial 23 finished with value: 0.973624814270203 and parameters: {'max_depth': 11, 'learning_rate': 0.014894843021344096, 'colsample_bytree': 0.2341491397225178, 'subsample': 0.8290377635776784, 'n_estimators': 557, 'min_child_weight': 8, 'reg_alpha': 0.09957217978475597, 'reg_lambda': 0.6122420021621396, 'gamma': 0.044983712143641046, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.973624814270203.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:48:46,872]\u001b[0m Trial 24 finished with value: 0.9708046583588819 and parameters: {'max_depth': 11, 'learning_rate': 0.00596350833465477, 'colsample_bytree': 0.22817936848966913, 'subsample': 0.8373708566087465, 'n_estimators': 549, 'min_child_weight': 8, 'reg_alpha': 0.0761608928285595, 'reg_lambda': 0.568995239121726, 'gamma': 0.06498289133102432, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 0.973624814270203.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:49:07,404]\u001b[0m Trial 25 finished with value: 0.9740144827913056 and parameters: {'max_depth': 13, 'learning_rate': 0.0160423019396275, 'colsample_bytree': 0.27110448854420177, 'subsample': 0.8588613853030432, 'n_estimators': 470, 'min_child_weight': 8, 'reg_alpha': 0.06484219794314798, 'reg_lambda': 0.5327561776837247, 'gamma': 0.0407486849377247, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 0.9740144827913056.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:49:21,059]\u001b[0m Trial 26 finished with value: 0.9660867864411524 and parameters: {'max_depth': 13, 'learning_rate': 0.001967962376083949, 'colsample_bytree': 0.2711789211311103, 'subsample': 0.8580100735471281, 'n_estimators': 471, 'min_child_weight': 9, 'reg_alpha': 0.06585976576895958, 'reg_lambda': 0.5036645633039164, 'gamma': 0.031336584755287944, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 0.9740144827913056.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:49:37,708]\u001b[0m Trial 27 finished with value: 0.9683956775312211 and parameters: {'max_depth': 15, 'learning_rate': 0.004550097943643533, 'colsample_bytree': 0.2734331153050923, 'subsample': 0.8790903977714575, 'n_estimators': 516, 'min_child_weight': 8, 'reg_alpha': 0.05226383102847159, 'reg_lambda': 0.7024045148924799, 'gamma': 0.04286755065608939, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 0.9740144827913056.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:49:57,639]\u001b[0m Trial 28 finished with value: 0.9734085921675651 and parameters: {'max_depth': 14, 'learning_rate': 0.021442720624516798, 'colsample_bytree': 0.2981916974324988, 'subsample': 0.8529981967373199, 'n_estimators': 477, 'min_child_weight': 9, 'reg_alpha': 0.10306962641347509, 'reg_lambda': 0.5350773465629776, 'gamma': 0.03282560390833481, 'grow_policy': 'depthwise'}. Best is trial 25 with value: 0.9740144827913056.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:50:19,265]\u001b[0m Trial 29 finished with value: 0.9745027800898473 and parameters: {'max_depth': 12, 'learning_rate': 0.018642286660178777, 'colsample_bytree': 0.27563851018608354, 'subsample': 0.8680182298469903, 'n_estimators': 542, 'min_child_weight': 7, 'reg_alpha': 0.02563265561003837, 'reg_lambda': 0.4498522307692631, 'gamma': 0.046192115604058816, 'grow_policy': 'depthwise'}. Best is trial 29 with value: 0.9745027800898473.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:50:35,425]\u001b[0m Trial 30 finished with value: 0.9665888595045014 and parameters: {'max_depth': 12, 'learning_rate': 0.0017571542551964906, 'colsample_bytree': 0.23983765372979776, 'subsample': 0.8686830686156538, 'n_estimators': 535, 'min_child_weight': 7, 'reg_alpha': 0.046823434975612664, 'reg_lambda': 0.4532126652349076, 'gamma': 0.045700389777828664, 'grow_policy': 'depthwise'}. Best is trial 29 with value: 0.9745027800898473.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:50:53,838]\u001b[0m Trial 31 finished with value: 0.9740677170506458 and parameters: {'max_depth': 10, 'learning_rate': 0.0213614366072984, 'colsample_bytree': 0.2647910519611622, 'subsample': 0.8833156349162187, 'n_estimators': 536, 'min_child_weight': 8, 'reg_alpha': 0.025010699922933075, 'reg_lambda': 0.5317789416138452, 'gamma': 0.042382446878197484, 'grow_policy': 'depthwise'}. Best is trial 29 with value: 0.9745027800898473.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:51:13,389]\u001b[0m Trial 32 finished with value: 0.9747123384822654 and parameters: {'max_depth': 12, 'learning_rate': 0.01834115817146378, 'colsample_bytree': 0.2622293651057247, 'subsample': 0.8844173323530695, 'n_estimators': 491, 'min_child_weight': 7, 'reg_alpha': 0.0020085139966095206, 'reg_lambda': 0.4563181480299012, 'gamma': 0.0375151804087786, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:51:29,846]\u001b[0m Trial 33 finished with value: 0.970736931821772 and parameters: {'max_depth': 12, 'learning_rate': 0.08864577723670435, 'colsample_bytree': 0.2806308742953487, 'subsample': 0.8875441321291669, 'n_estimators': 482, 'min_child_weight': 7, 'reg_alpha': 0.006442589660523024, 'reg_lambda': 0.46669066498915485, 'gamma': 0.024866805420991664, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:52:17,653]\u001b[0m Trial 34 finished with value: 0.9728359460692175 and parameters: {'max_depth': 14, 'learning_rate': 0.007203058681619777, 'colsample_bytree': 0.26446322490002466, 'subsample': 0.9066998392630836, 'n_estimators': 458, 'min_child_weight': 5, 'reg_alpha': 0.03802954403020877, 'reg_lambda': 0.4170073693874944, 'gamma': 0.0386558470351754, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:52:30,675]\u001b[0m Trial 35 finished with value: 0.9718382122446819 and parameters: {'max_depth': 10, 'learning_rate': 0.0718413045443371, 'colsample_bytree': 0.25388998378257716, 'subsample': 0.8736947448057174, 'n_estimators': 400, 'min_child_weight': 9, 'reg_alpha': 0.001853248270717508, 'reg_lambda': 0.5313962421293849, 'gamma': 0.03580350225300655, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:52:52,071]\u001b[0m Trial 36 finished with value: 0.9739677460335253 and parameters: {'max_depth': 14, 'learning_rate': 0.03518190918977352, 'colsample_bytree': 0.2822140989180315, 'subsample': 0.9036601596647225, 'n_estimators': 497, 'min_child_weight': 7, 'reg_alpha': 0.031679618554414105, 'reg_lambda': 0.48146705536062917, 'gamma': 0.02545072659663147, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:53:05,106]\u001b[0m Trial 37 finished with value: 0.9725472346435028 and parameters: {'max_depth': 12, 'learning_rate': 0.058906008097257975, 'colsample_bytree': 0.2644067432314598, 'subsample': 0.8615487470178482, 'n_estimators': 362, 'min_child_weight': 9, 'reg_alpha': 0.029555086494143807, 'reg_lambda': 0.4342774939686489, 'gamma': 0.04152918905733011, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:53:48,557]\u001b[0m Trial 38 finished with value: 0.973451999165303 and parameters: {'max_depth': 16, 'learning_rate': 0.01872062641491507, 'colsample_bytree': 0.2997700968107467, 'subsample': 0.8825484475362827, 'n_estimators': 531, 'min_child_weight': 10, 'reg_alpha': 0.06566431517566411, 'reg_lambda': 0.39837529478504874, 'gamma': 0.0517605635874093, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:54:04,440]\u001b[0m Trial 39 finished with value: 0.9692604569982805 and parameters: {'max_depth': 10, 'learning_rate': 0.11866698200661246, 'colsample_bytree': 0.26121274352367063, 'subsample': 0.8674981779185018, 'n_estimators': 499, 'min_child_weight': 8, 'reg_alpha': 0.0034697416604257333, 'reg_lambda': 0.32283201061666, 'gamma': 0.06073402069190943, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:55:02,358]\u001b[0m Trial 40 finished with value: 0.9730210955327319 and parameters: {'max_depth': 15, 'learning_rate': 0.006354504128890301, 'colsample_bytree': 0.2765389698475915, 'subsample': 0.8933219606560807, 'n_estimators': 446, 'min_child_weight': 5, 'reg_alpha': 0.047841565309232406, 'reg_lambda': 0.2583311086740248, 'gamma': 0.018968616412129387, 'grow_policy': 'lossguide'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:55:26,636]\u001b[0m Trial 41 finished with value: 0.9731001703501887 and parameters: {'max_depth': 14, 'learning_rate': 0.029370971157560793, 'colsample_bytree': 0.2885706188789363, 'subsample': 0.9037449248968721, 'n_estimators': 491, 'min_child_weight': 7, 'reg_alpha': 0.027722310135891572, 'reg_lambda': 0.48840300036851375, 'gamma': 0.027905129531984506, 'grow_policy': 'depthwise'}. Best is trial 32 with value: 0.9747123384822654.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:55:52,420]\u001b[0m Trial 42 finished with value: 0.9750382317628861 and parameters: {'max_depth': 13, 'learning_rate': 0.019178145039892347, 'colsample_bytree': 0.2768239785928682, 'subsample': 0.9109770499580926, 'n_estimators': 508, 'min_child_weight': 6, 'reg_alpha': 0.025118523585543086, 'reg_lambda': 0.46319087575056983, 'gamma': 0.034948457251703216, 'grow_policy': 'depthwise'}. Best is trial 42 with value: 0.9750382317628861.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:56:16,068]\u001b[0m Trial 43 finished with value: 0.9750384510465802 and parameters: {'max_depth': 13, 'learning_rate': 0.016474009154216287, 'colsample_bytree': 0.27492493169509574, 'subsample': 0.9177187561606172, 'n_estimators': 530, 'min_child_weight': 6, 'reg_alpha': 0.06728015878725187, 'reg_lambda': 0.3850044956052784, 'gamma': 0.03479209631794973, 'grow_policy': 'depthwise'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:56:37,289]\u001b[0m Trial 44 finished with value: 0.9739929022030424 and parameters: {'max_depth': 12, 'learning_rate': 0.009029790736990081, 'colsample_bytree': 0.27936671299803134, 'subsample': 0.9170907951233057, 'n_estimators': 517, 'min_child_weight': 6, 'reg_alpha': 0.0270705306629226, 'reg_lambda': 0.3780385106493482, 'gamma': 0.03591138825434045, 'grow_policy': 'depthwise'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:56:57,322]\u001b[0m Trial 45 finished with value: 0.9700792036501187 and parameters: {'max_depth': 11, 'learning_rate': 0.08112139642793452, 'colsample_bytree': 0.25479995273057326, 'subsample': 0.9174171833354412, 'n_estimators': 574, 'min_child_weight': 5, 'reg_alpha': 0.0857881585748992, 'reg_lambda': 0.4309885806744491, 'gamma': 0.03061988703212238, 'grow_policy': 'depthwise'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:58:07,502]\u001b[0m Trial 46 finished with value: 0.9744748193237841 and parameters: {'max_depth': 13, 'learning_rate': 0.009568227697248861, 'colsample_bytree': 0.28703099029314566, 'subsample': 0.8755223449671363, 'n_estimators': 540, 'min_child_weight': 6, 'reg_alpha': 0.012582566729982047, 'reg_lambda': 0.36936491347992895, 'gamma': 0.03511017227309543, 'grow_policy': 'lossguide'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 18:59:24,335]\u001b[0m Trial 47 finished with value: 0.9727473359028467 and parameters: {'max_depth': 16, 'learning_rate': 0.00392741218364906, 'colsample_bytree': 0.29155239462300303, 'subsample': 0.8983051309947595, 'n_estimators': 557, 'min_child_weight': 6, 'reg_alpha': 0.007453428332738062, 'reg_lambda': 0.26412519773429854, 'gamma': 0.01879763686599589, 'grow_policy': 'lossguide'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 19:00:27,369]\u001b[0m Trial 48 finished with value: 0.9748738011166842 and parameters: {'max_depth': 13, 'learning_rate': 0.009097834456944913, 'colsample_bytree': 0.29105407530286265, 'subsample': 0.9169004163673532, 'n_estimators': 514, 'min_child_weight': 5, 'reg_alpha': 0.046817828641427334, 'reg_lambda': 0.34044041532314573, 'gamma': 0.034357534576058786, 'grow_policy': 'lossguide'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 19:01:01,868]\u001b[0m Trial 49 finished with value: 0.9663036761718523 and parameters: {'max_depth': 13, 'learning_rate': 0.0010693410970782939, 'colsample_bytree': 0.2777524330838164, 'subsample': 0.9245117754828833, 'n_estimators': 518, 'min_child_weight': 5, 'reg_alpha': 0.12102300084964425, 'reg_lambda': 0.32950445375136, 'gamma': 0.029870138507833197, 'grow_policy': 'lossguide'}. Best is trial 43 with value: 0.9750384510465802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'max_depth': 13, 'learning_rate': 0.016474009154216287, 'colsample_bytree': 0.27492493169509574, 'subsample': 0.9177187561606172, 'n_estimators': 530, 'min_child_weight': 6, 'reg_alpha': 0.06728015878725187, 'reg_lambda': 0.3850044956052784, 'gamma': 0.03479209631794973, 'grow_policy': 'depthwise'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 18),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.15, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.00001, 0.1),\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'tree_method': 'gpu_hist',\n",
    "    }\n",
    "\n",
    "    \n",
    "    model_XGB = xgb.XGBClassifier(**params, n_jobs = -1)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    y_pred_proba = cross_val_predict(model_XGB, X_train, y_train, cv=cv, method='predict_proba')[:,1]\n",
    "    auc = roc_auc_score(y_train, y_pred_proba)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_XGB = study.best_params\n",
    "print(\"Best: \", best_XGB)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_xgb2 = {'max_depth': 13, \n",
    "            'learning_rate': 0.016474009154216287, \n",
    "            'colsample_bytree': 0.27492493169509574, \n",
    "            'subsample': 0.9177187561606172, \n",
    "            'n_estimators': 530, \n",
    "            'min_child_weight': 6, \n",
    "            'reg_alpha': 0.06728015878725187, \n",
    "            'reg_lambda': 0.3850044956052784, \n",
    "            'gamma': 0.03479209631794973, \n",
    "            'grow_policy': 'depthwise',\n",
    "            'booster': 'gbtree',\n",
    "            'objective': 'binary:logistic',\n",
    "            'tree_method': 'gpu_hist',} #Best 0.9750384510465802\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_XGB =  {'max_depth': 13, \n",
    "         'learning_rate': 0.012308520402322306, \n",
    "         'colsample_bytree': 0.15564433647290904, \n",
    "         'subsample': 0.9392376085401448, \n",
    "         'n_estimators': 494, \n",
    "         'min_child_weight': 1, \n",
    "         'reg_alpha': 0.26760253520809857, \n",
    "         'reg_lambda': 0.24616802866656362} # best value: 0.9743947392021206."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.15564433647290904, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012308520402322306,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=494, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.15564433647290904, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012308520402322306,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=494, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.15564433647290904, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012308520402322306,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=494, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_XGB = xgb.XGBClassifier(**Best_XGB)\n",
    "model_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC XGB:  0.9794722807448966\n"
     ]
    }
   ],
   "source": [
    "AUC_XGB = ROC_AUC(model_XGB, X_train, y_train)\n",
    "print(\"AUC XGB: \", AUC_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_XGB.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC XGB:  0.9794722807448966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC XGB:  0.9754890580872562"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_CAT = y_train\n",
    "X_train_CAT = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[I 2023-06-21 06:15:44,113]\u001b[0m A new study created in memory with name: no-name-7a378e77-1fa3-4d47-b4f4-9b6c9a5df6e8\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:15:55,160]\u001b[0m Trial 0 finished with value: 0.9734898592275569 and parameters: {'iterations': 118, 'depth': 8, 'learning_rate': 0.03337627092412684, 'random_strength': 38, 'bagging_temperature': 0.6630721421099399, 'od_type': 'IncToDec', 'od_wait': 41}. Best is trial 0 with value: 0.9734898592275569.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:16:01,367]\u001b[0m Trial 1 finished with value: 0.958876001875122 and parameters: {'iterations': 95, 'depth': 4, 'learning_rate': 0.018201277955057153, 'random_strength': 67, 'bagging_temperature': 1.6558340311284774, 'od_type': 'Iter', 'od_wait': 44}. Best is trial 0 with value: 0.9734898592275569.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:16:45,692]\u001b[0m Trial 2 finished with value: 0.9772358139676354 and parameters: {'iterations': 257, 'depth': 5, 'learning_rate': 0.016013653180670353, 'random_strength': 12, 'bagging_temperature': 13.192553631518582, 'od_type': 'IncToDec', 'od_wait': 33}. Best is trial 2 with value: 0.9772358139676354.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:17:01,780]\u001b[0m Trial 3 finished with value: 0.9698911284870575 and parameters: {'iterations': 189, 'depth': 7, 'learning_rate': 0.01838441938324979, 'random_strength': 38, 'bagging_temperature': 0.4580459600052331, 'od_type': 'IncToDec', 'od_wait': 40}. Best is trial 2 with value: 0.9772358139676354.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:17:48,542]\u001b[0m Trial 4 finished with value: 0.9726382020555282 and parameters: {'iterations': 257, 'depth': 6, 'learning_rate': 0.010661772773628595, 'random_strength': 18, 'bagging_temperature': 0.025026239357640808, 'od_type': 'IncToDec', 'od_wait': 20}. Best is trial 2 with value: 0.9772358139676354.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:17:54,129]\u001b[0m Trial 5 finished with value: 0.9747909201279744 and parameters: {'iterations': 70, 'depth': 4, 'learning_rate': 0.06961530152929896, 'random_strength': 1, 'bagging_temperature': 11.195121389883248, 'od_type': 'Iter', 'od_wait': 32}. Best is trial 2 with value: 0.9772358139676354.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:18:10,843]\u001b[0m Trial 6 finished with value: 0.9802838561139681 and parameters: {'iterations': 192, 'depth': 6, 'learning_rate': 0.13298695008637992, 'random_strength': 96, 'bagging_temperature': 23.38968224422692, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:02,632]\u001b[0m Trial 7 finished with value: 0.9745122379522403 and parameters: {'iterations': 267, 'depth': 7, 'learning_rate': 0.011204293096166808, 'random_strength': 84, 'bagging_temperature': 3.8984555598424446, 'od_type': 'IncToDec', 'od_wait': 44}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:09,465]\u001b[0m Trial 8 finished with value: 0.966511147578756 and parameters: {'iterations': 58, 'depth': 7, 'learning_rate': 0.01875789768517847, 'random_strength': 82, 'bagging_temperature': 0.0811330659785615, 'od_type': 'Iter', 'od_wait': 24}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:17,624]\u001b[0m Trial 9 finished with value: 0.977964871993275 and parameters: {'iterations': 85, 'depth': 4, 'learning_rate': 0.06538074501705872, 'random_strength': 3, 'bagging_temperature': 0.06620911360138529, 'od_type': 'IncToDec', 'od_wait': 43}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:33,769]\u001b[0m Trial 10 finished with value: 0.9801163362870465 and parameters: {'iterations': 172, 'depth': 6, 'learning_rate': 0.18816729296927456, 'random_strength': 95, 'bagging_temperature': 82.2348535848921, 'od_type': 'Iter', 'od_wait': 12}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:40,410]\u001b[0m Trial 11 finished with value: 0.9431041437148767 and parameters: {'iterations': 177, 'depth': 6, 'learning_rate': 0.19443445774516685, 'random_strength': 99, 'bagging_temperature': 81.40563734671218, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:19:50,208]\u001b[0m Trial 12 finished with value: 0.9714686012776825 and parameters: {'iterations': 213, 'depth': 5, 'learning_rate': 0.1897452002698456, 'random_strength': 66, 'bagging_temperature': 55.48962775331289, 'od_type': 'Iter', 'od_wait': 10}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:20:02,352]\u001b[0m Trial 13 finished with value: 0.9796431500224521 and parameters: {'iterations': 138, 'depth': 5, 'learning_rate': 0.12855314483784566, 'random_strength': 99, 'bagging_temperature': 97.64618076557574, 'od_type': 'Iter', 'od_wait': 50}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:20:34,881]\u001b[0m Trial 14 finished with value: 0.9785728479745085 and parameters: {'iterations': 205, 'depth': 6, 'learning_rate': 0.11921196727831093, 'random_strength': 81, 'bagging_temperature': 19.338512994684272, 'od_type': 'Iter', 'od_wait': 19}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:20:49,371]\u001b[0m Trial 15 finished with value: 0.9773342853692184 and parameters: {'iterations': 143, 'depth': 8, 'learning_rate': 0.12154986900019453, 'random_strength': 64, 'bagging_temperature': 32.75219979959491, 'od_type': 'Iter', 'od_wait': 25}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:21:42,015]\u001b[0m Trial 16 finished with value: 0.9801355718389281 and parameters: {'iterations': 230, 'depth': 7, 'learning_rate': 0.08603869659838666, 'random_strength': 91, 'bagging_temperature': 8.653794689608256, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[32m[I 2023-06-21 06:22:32,785]\u001b[0m Trial 17 finished with value: 0.9798934258737616 and parameters: {'iterations': 228, 'depth': 7, 'learning_rate': 0.0763476872705869, 'random_strength': 45, 'bagging_temperature': 3.9339901763515974, 'od_type': 'Iter', 'od_wait': 36}. Best is trial 6 with value: 0.9802838561139681.\u001b[0m\n",
      "\u001b[33m[W 2023-06-21 06:23:12,624]\u001b[0m Trial 18 failed with parameters: {'iterations': 234, 'depth': 8, 'learning_rate': 0.04791221907773429, 'random_strength': 87, 'bagging_temperature': 9.933910984669817, 'od_type': 'Iter', 'od_wait': 27} because of the following error: KeyboardInterrupt('').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_10496\\3538752553.py\", line 28, in objective\n",
      "    model_CAT.fit(train_pool, eval_set=valid_pool)\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 5131, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 2357, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 1761, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-06-21 06:23:12,628]\u001b[0m Trial 18 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[39m# Start optimization\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     25\u001b[0m     train_pool \u001b[39m=\u001b[39m Pool(data\u001b[39m=\u001b[39mX_train_CAT\u001b[39m.\u001b[39miloc[train_index], label\u001b[39m=\u001b[39my_train_CAT\u001b[39m.\u001b[39miloc[train_index], cat_features \u001b[39m=\u001b[39m cat_columns)\n\u001b[0;32m     26\u001b[0m     valid_pool \u001b[39m=\u001b[39m Pool(data\u001b[39m=\u001b[39mX_train_CAT\u001b[39m.\u001b[39miloc[valid_index], label\u001b[39m=\u001b[39my_train_CAT\u001b[39m.\u001b[39miloc[valid_index], cat_features \u001b[39m=\u001b[39m cat_columns)\n\u001b[1;32m---> 28\u001b[0m     model_CAT\u001b[39m.\u001b[39;49mfit(train_pool, eval_set\u001b[39m=\u001b[39;49mvalid_pool)\n\u001b[0;32m     29\u001b[0m     scores\u001b[39m.\u001b[39mappend(model_CAT\u001b[39m.\u001b[39mbest_score_[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(scores)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:5131\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5129\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5131\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5132\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5133\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:2357\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2353\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2355\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2356\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2358\u001b[0m         train_pool,\n\u001b[0;32m   2359\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2360\u001b[0m         params,\n\u001b[0;32m   2361\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2362\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2363\u001b[0m     )\n\u001b[0;32m   2365\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py:1761\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1761\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4624\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4673\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Specify a search space using trial object\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True), \n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 100.00, log=True), \n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "        'od_wait': trial.suggest_int('od_wait', 10, 50),\n",
    "        'loss_function': 'Logloss',  # Binary classification\n",
    "        'eval_metric': 'AUC',  # AUC as the performance metric\n",
    "    }\n",
    "\n",
    "    model_CAT = CatBoostClassifier(**params, verbose=False)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    scores = []\n",
    "    for train_index, valid_index in cv.split(X_train_CAT, y_train_CAT):\n",
    "        train_pool = Pool(data=X_train_CAT.iloc[train_index], label=y_train_CAT.iloc[train_index], cat_features = cat_columns)\n",
    "        valid_pool = Pool(data=X_train_CAT.iloc[valid_index], label=y_train_CAT.iloc[valid_index], cat_features = cat_columns)\n",
    "\n",
    "        model_CAT.fit(train_pool, eval_set=valid_pool)\n",
    "        scores.append(model_CAT.best_score_['validation']['AUC'])\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(objective, n_trials=50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2023-06-17 11:51:23,335] Trial 11 finished with value: 0.9783593516221193 and parameters: {'iterations': 248, 'depth': 8, 'learning_rate': 0.07556114402524425, 'random_strength': 2, 'bagging_temperature': 1.6353270643758222, 'od_type': 'Iter', 'od_wait': 22}. Best is trial 11 with value: 0.9783593516221193.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Cat_Opt_AllCat = {'iterations': 192, \n",
    "                        'depth': 6,\n",
    "                        'learning_rate': 0.13298695008637992, \n",
    "                        'random_strength': 96, \n",
    "                        'bagging_temperature': 23.38968224422692, \n",
    "                        'od_type': 'Iter', \n",
    "                        'od_wait': 36\n",
    "                        } #Best is trial 6 with value: 0.9802838561139681.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_CAT = {'iterations': 290, \n",
    "            'depth': 12, \n",
    "            'learning_rate': 0.016041043108679078, \n",
    "            'random_strength': 12, \n",
    "            'bagging_temperature': 0.014032128937182435, \n",
    "            'od_type': 'IncToDec', \n",
    "            'od_wait': 47}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CAT.drop(columns = ['Machine_failure'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x277c225a790>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "model_CAT = CatBoostClassifier(**Best_Cat_Opt_AllCat, cat_features = cat_columns, verbose=False)\n",
    "model_CAT.fit(X_train_CAT, y_train_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_CAT[cat_columns] = X_test_CAT[cat_columns].astype('category')\n",
    "X_train_CAT[cat_columns] = X_train_CAT[cat_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   31.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "score = cross_val_score(model_CAT, X_train_CAT, y_train_CAT, cv=cv2, n_jobs=-1, verbose=1, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC CAT:  0.9799481201707483\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC CAT: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_CAT.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-19 06:37:32,282]\u001b[0m A new study created in memory with name: no-name-8b291dda-fda5-4161-b858-708e5ff96aee\u001b[0m\n",
      "\u001b[33m[W 2023-06-19 06:46:12,572]\u001b[0m Trial 0 failed with parameters: {'n_estimators': 128, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 3, 'learning_rate': 0.013447672137663734} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_8156\\4039872000.py\", line 23, in objective\n",
      "    score = cross_val_score(model, X_train, y_train, cv=strat_kfold, scoring=\"roc_auc\")\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 538, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 615, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 257, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 379, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-06-19 06:46:12,576]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m roc_auc\n\u001b[0;32m     27\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Muestra los mejores parámetros\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[14], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     14\u001b[0m strat_kfold \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     16\u001b[0m model \u001b[39m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, \n\u001b[0;32m     17\u001b[0m                                    max_depth\u001b[39m=\u001b[39mmax_depth, \n\u001b[0;32m     18\u001b[0m                                    min_samples_split\u001b[39m=\u001b[39mmin_samples_split, \n\u001b[0;32m     19\u001b[0m                                    min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf,\n\u001b[0;32m     20\u001b[0m                                    learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m     21\u001b[0m                                    random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[39m=\u001b[39;49mstrat_kfold, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     24\u001b[0m roc_auc \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m roc_auc\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    259\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 16)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1, log=True)\n",
    "\n",
    "    strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_split=min_samples_split, \n",
    "                                       min_samples_leaf=min_samples_leaf,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_train, y_train, cv=strat_kfold, scoring=\"roc_auc\")\n",
    "    roc_auc = score.mean()\n",
    "    return roc_auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Muestra los mejores parámetros\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-19 06:50:46,192]\u001b[0m A new study created in memory with name: no-name-127648be-2b2d-418c-947e-988ab33583ed\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:51:08,768]\u001b[0m Trial 0 finished with value: 0.9695277072482027 and parameters: {'max_iter': 753, 'max_depth': 16, 'min_samples_leaf': 1, 'l2_regularization': 0.5932723023081404, 'learning_rate': 0.03824436300967314}. Best is trial 0 with value: 0.9695277072482027.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:51:23,807]\u001b[0m Trial 1 finished with value: 0.9697791003028786 and parameters: {'max_iter': 956, 'max_depth': 44, 'min_samples_leaf': 5, 'l2_regularization': 0.6347878379750351, 'learning_rate': 0.07254069710263998}. Best is trial 1 with value: 0.9697791003028786.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:51:40,914]\u001b[0m Trial 2 finished with value: 0.9691692746192763 and parameters: {'max_iter': 625, 'max_depth': 13, 'min_samples_leaf': 20, 'l2_regularization': 0.013610801663519467, 'learning_rate': 0.04962425909010801}. Best is trial 1 with value: 0.9697791003028786.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:51:45,797]\u001b[0m Trial 3 finished with value: 0.9688269822856306 and parameters: {'max_iter': 683, 'max_depth': 46, 'min_samples_leaf': 16, 'l2_regularization': 0.042729884081028846, 'learning_rate': 0.1888478443181049}. Best is trial 1 with value: 0.9697791003028786.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:52:08,391]\u001b[0m Trial 4 finished with value: 0.967850768169035 and parameters: {'max_iter': 186, 'max_depth': 31, 'min_samples_leaf': 8, 'l2_regularization': 0.2620073897982831, 'learning_rate': 0.016815457922523928}. Best is trial 1 with value: 0.9697791003028786.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:52:27,261]\u001b[0m Trial 5 finished with value: 0.9701857577438651 and parameters: {'max_iter': 965, 'max_depth': 33, 'min_samples_leaf': 10, 'l2_regularization': 0.6771577261409922, 'learning_rate': 0.05143800005080897}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:52:34,958]\u001b[0m Trial 6 finished with value: 0.9697231336405446 and parameters: {'max_iter': 740, 'max_depth': 19, 'min_samples_leaf': 13, 'l2_regularization': 0.5402869147661646, 'learning_rate': 0.14629790261127332}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:52:50,360]\u001b[0m Trial 7 finished with value: 0.9698760204132331 and parameters: {'max_iter': 826, 'max_depth': 48, 'min_samples_leaf': 5, 'l2_regularization': 0.9701695178909308, 'learning_rate': 0.057510681882349896}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:53:04,712]\u001b[0m Trial 8 finished with value: 0.9688514483180726 and parameters: {'max_iter': 367, 'max_depth': 18, 'min_samples_leaf': 8, 'l2_regularization': 0.8569890115484196, 'learning_rate': 0.06363412602345736}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:53:36,843]\u001b[0m Trial 9 finished with value: 0.9694512402157581 and parameters: {'max_iter': 480, 'max_depth': 46, 'min_samples_leaf': 4, 'l2_regularization': 0.5683616664481318, 'learning_rate': 0.026162065713934753}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:53:50,694]\u001b[0m Trial 10 finished with value: 0.9701258614073638 and parameters: {'max_iter': 919, 'max_depth': 34, 'min_samples_leaf': 13, 'l2_regularization': 0.7768287042473442, 'learning_rate': 0.10093335776772289}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:54:02,863]\u001b[0m Trial 11 finished with value: 0.9693246124470012 and parameters: {'max_iter': 999, 'max_depth': 33, 'min_samples_leaf': 13, 'l2_regularization': 0.7669663820948565, 'learning_rate': 0.10915562846953304}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:54:14,724]\u001b[0m Trial 12 finished with value: 0.9696739823723022 and parameters: {'max_iter': 870, 'max_depth': 37, 'min_samples_leaf': 11, 'l2_regularization': 0.7576576906653409, 'learning_rate': 0.09945986544080193}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:55:11,853]\u001b[0m Trial 13 finished with value: 0.9689317863743947 and parameters: {'max_iter': 904, 'max_depth': 38, 'min_samples_leaf': 16, 'l2_regularization': 0.43183851547736085, 'learning_rate': 0.012767999795548518}. Best is trial 5 with value: 0.9701857577438651.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:55:23,252]\u001b[0m Trial 14 finished with value: 0.9703847168382816 and parameters: {'max_iter': 527, 'max_depth': 25, 'min_samples_leaf': 10, 'l2_regularization': 0.9768233208623924, 'learning_rate': 0.0922488541643394}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:55:36,272]\u001b[0m Trial 15 finished with value: 0.9697871234874654 and parameters: {'max_iter': 508, 'max_depth': 24, 'min_samples_leaf': 9, 'l2_regularization': 0.9919136961712824, 'learning_rate': 0.08538841383234566}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:55:58,255]\u001b[0m Trial 16 finished with value: 0.9697041929171792 and parameters: {'max_iter': 314, 'max_depth': 7, 'min_samples_leaf': 10, 'l2_regularization': 0.895120854252119, 'learning_rate': 0.03967749991604572}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:56:08,195]\u001b[0m Trial 17 finished with value: 0.9687361459669039 and parameters: {'max_iter': 597, 'max_depth': 27, 'min_samples_leaf': 16, 'l2_regularization': 0.6670211188585964, 'learning_rate': 0.12597259169415126}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:56:22,090]\u001b[0m Trial 18 finished with value: 0.9690817878442475 and parameters: {'max_iter': 405, 'max_depth': 25, 'min_samples_leaf': 7, 'l2_regularization': 0.864997371603118, 'learning_rate': 0.07592303262158238}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:56:49,826]\u001b[0m Trial 19 finished with value: 0.9572129306028438 and parameters: {'max_iter': 227, 'max_depth': 40, 'min_samples_leaf': 11, 'l2_regularization': 0.4220136496049084, 'learning_rate': 0.0015668872036923298}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:57:08,432]\u001b[0m Trial 20 finished with value: 0.9701811914375094 and parameters: {'max_iter': 462, 'max_depth': 22, 'min_samples_leaf': 20, 'l2_regularization': 0.7068463818678434, 'learning_rate': 0.05119665547160799}. Best is trial 14 with value: 0.9703847168382816.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:57:24,561]\u001b[0m Trial 21 finished with value: 0.9708572700192338 and parameters: {'max_iter': 465, 'max_depth': 23, 'min_samples_leaf': 19, 'l2_regularization': 0.6937970904634575, 'learning_rate': 0.05507960310469436}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:57:38,659]\u001b[0m Trial 22 finished with value: 0.970184319977708 and parameters: {'max_iter': 568, 'max_depth': 30, 'min_samples_leaf': 18, 'l2_regularization': 0.684241421062894, 'learning_rate': 0.08188654097488617}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:58:03,489]\u001b[0m Trial 23 finished with value: 0.9699290554329254 and parameters: {'max_iter': 290, 'max_depth': 11, 'min_samples_leaf': 14, 'l2_regularization': 0.8253057631434453, 'learning_rate': 0.03628046244483375}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:58:18,931]\u001b[0m Trial 24 finished with value: 0.968961238541738 and parameters: {'max_iter': 410, 'max_depth': 28, 'min_samples_leaf': 10, 'l2_regularization': 0.9688768313101677, 'learning_rate': 0.06198867813608787}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:58:32,163]\u001b[0m Trial 25 finished with value: 0.9699600553007907 and parameters: {'max_iter': 662, 'max_depth': 22, 'min_samples_leaf': 7, 'l2_regularization': 0.7357451984322438, 'learning_rate': 0.08811809473114822}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:58:46,655]\u001b[0m Trial 26 finished with value: 0.9697208173765469 and parameters: {'max_iter': 544, 'max_depth': 35, 'min_samples_leaf': 12, 'l2_regularization': 0.9229949337828749, 'learning_rate': 0.06768165852143966}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:59:08,422]\u001b[0m Trial 27 finished with value: 0.9699409898236115 and parameters: {'max_iter': 787, 'max_depth': 29, 'min_samples_leaf': 2, 'l2_regularization': 0.8145356527448178, 'learning_rate': 0.049260045897641505}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:59:21,933]\u001b[0m Trial 28 finished with value: 0.9682991661563017 and parameters: {'max_iter': 108, 'max_depth': 41, 'min_samples_leaf': 15, 'l2_regularization': 0.6422523379717766, 'learning_rate': 0.03648199829943509}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 06:59:34,940]\u001b[0m Trial 29 finished with value: 0.9695669534211844 and parameters: {'max_iter': 731, 'max_depth': 19, 'min_samples_leaf': 18, 'l2_regularization': 0.9023782392806213, 'learning_rate': 0.07125382305108091}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:00:03,841]\u001b[0m Trial 30 finished with value: 0.9705601129169505 and parameters: {'max_iter': 442, 'max_depth': 15, 'min_samples_leaf': 18, 'l2_regularization': 0.6132657830230303, 'learning_rate': 0.026556628234388716}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:00:34,337]\u001b[0m Trial 31 finished with value: 0.9699846460841505 and parameters: {'max_iter': 465, 'max_depth': 11, 'min_samples_leaf': 18, 'l2_regularization': 0.6026433811600284, 'learning_rate': 0.023788772982670063}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:00:55,026]\u001b[0m Trial 32 finished with value: 0.9698612956111832 and parameters: {'max_iter': 360, 'max_depth': 15, 'min_samples_leaf': 19, 'l2_regularization': 0.6994772265581597, 'learning_rate': 0.03963911229523584}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:01:10,763]\u001b[0m Trial 33 finished with value: 0.9696733122732087 and parameters: {'max_iter': 522, 'max_depth': 22, 'min_samples_leaf': 17, 'l2_regularization': 0.6196506532826863, 'learning_rate': 0.05976883712456886}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:01:28,933]\u001b[0m Trial 34 finished with value: 0.9690451935324372 and parameters: {'max_iter': 628, 'max_depth': 6, 'min_samples_leaf': 20, 'l2_regularization': 0.8193520829864436, 'learning_rate': 0.04819734448120513}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:01:56,359]\u001b[0m Trial 35 finished with value: 0.969423343356371 and parameters: {'max_iter': 436, 'max_depth': 14, 'min_samples_leaf': 9, 'l2_regularization': 0.5360577268538983, 'learning_rate': 0.02697638325651766}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:02:10,005]\u001b[0m Trial 36 finished with value: 0.969813348899405 and parameters: {'max_iter': 573, 'max_depth': 26, 'min_samples_leaf': 15, 'l2_regularization': 0.6402341680710021, 'learning_rate': 0.07377648875491204}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:03:21,238]\u001b[0m Trial 37 finished with value: 0.9701432535880343 and parameters: {'max_iter': 705, 'max_depth': 17, 'min_samples_leaf': 6, 'l2_regularization': 0.4919210060562472, 'learning_rate': 0.010092770892810302}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:03:38,765]\u001b[0m Trial 38 finished with value: 0.9704951180485711 and parameters: {'max_iter': 301, 'max_depth': 21, 'min_samples_leaf': 12, 'l2_regularization': 0.7162612468449404, 'learning_rate': 0.05483661132929285}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:03:54,140]\u001b[0m Trial 39 finished with value: 0.970261781813923 and parameters: {'max_iter': 245, 'max_depth': 19, 'min_samples_leaf': 17, 'l2_regularization': 0.7197480144556874, 'learning_rate': 0.05830765013248373}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:04:26,317]\u001b[0m Trial 40 finished with value: 0.9701682004788015 and parameters: {'max_iter': 372, 'max_depth': 12, 'min_samples_leaf': 12, 'l2_regularization': 0.9443261067446697, 'learning_rate': 0.025663182896609658}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:04:43,053]\u001b[0m Trial 41 finished with value: 0.9692314624094707 and parameters: {'max_iter': 211, 'max_depth': 20, 'min_samples_leaf': 19, 'l2_regularization': 0.7800919653877915, 'learning_rate': 0.05824372807856848}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:05:01,029]\u001b[0m Trial 42 finished with value: 0.9685049753358067 and parameters: {'max_iter': 261, 'max_depth': 23, 'min_samples_leaf': 17, 'l2_regularization': 0.7307816666816015, 'learning_rate': 0.04283399898620469}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:05:15,383]\u001b[0m Trial 43 finished with value: 0.9700777198562902 and parameters: {'max_iter': 160, 'max_depth': 16, 'min_samples_leaf': 19, 'l2_regularization': 0.6031621684129649, 'learning_rate': 0.06449708011698715}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:05:30,885]\u001b[0m Trial 44 finished with value: 0.9681914326311952 and parameters: {'max_iter': 330, 'max_depth': 20, 'min_samples_leaf': 17, 'l2_regularization': 0.7090599550061929, 'learning_rate': 0.05544685509792975}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:05:55,284]\u001b[0m Trial 45 finished with value: 0.9693735853872925 and parameters: {'max_iter': 277, 'max_depth': 18, 'min_samples_leaf': 15, 'l2_regularization': 0.8608476465445645, 'learning_rate': 0.03419036630322371}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:06:10,654]\u001b[0m Trial 46 finished with value: 0.9698063744892755 and parameters: {'max_iter': 145, 'max_depth': 25, 'min_samples_leaf': 14, 'l2_regularization': 0.7956027933941237, 'learning_rate': 0.0521826488382591}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:06:28,405]\u001b[0m Trial 47 finished with value: 0.9698512679877004 and parameters: {'max_iter': 510, 'max_depth': 9, 'min_samples_leaf': 20, 'l2_regularization': 0.7413938483670937, 'learning_rate': 0.04700809246374568}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:06:43,542]\u001b[0m Trial 48 finished with value: 0.9700898193579418 and parameters: {'max_iter': 401, 'max_depth': 21, 'min_samples_leaf': 12, 'l2_regularization': 0.665670812336281, 'learning_rate': 0.06935452388228965}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 07:06:55,406]\u001b[0m Trial 49 finished with value: 0.9698813197321297 and parameters: {'max_iter': 240, 'max_depth': 32, 'min_samples_leaf': 14, 'l2_regularization': 0.5673351385161496, 'learning_rate': 0.0805974572166886}. Best is trial 21 with value: 0.9708572700192338.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.0, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.2),\n",
    "    }\n",
    "\n",
    "    model = HistGradientBoostingClassifier(**params)\n",
    "\n",
    "    strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=strat_kfold, scoring='roc_auc')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Luego de que se complete la optimización, puedes obtener los mejores parámetros así:\n",
    "best_params = study.best_params\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "best_Hist = {'max_iter': 465, \n",
    "             'max_depth': 23, \n",
    "             'min_samples_leaf': 19, \n",
    "             'l2_regularization': 0.6937970904634575, \n",
    "             'learning_rate': 0.05507960310469436} #0.9708572700192338.\n",
    "\n",
    "model_Hist = HistGradientBoostingClassifier(**best_Hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier(l2_regularization=0.6937970904634575,\n",
       "                               learning_rate=0.05507960310469436, max_depth=23,\n",
       "                               max_iter=465, min_samples_leaf=19)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(l2_regularization=0.6937970904634575,\n",
       "                               learning_rate=0.05507960310469436, max_depth=23,\n",
       "                               max_iter=465, min_samples_leaf=19)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier(l2_regularization=0.6937970904634575,\n",
       "                               learning_rate=0.05507960310469436, max_depth=23,\n",
       "                               max_iter=465, min_samples_leaf=19)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Hist.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC LGBM:  0.9697346782390577\n"
     ]
    }
   ],
   "source": [
    "AUC = ROC_AUC(model_Hist, X_train, y_train)\n",
    "print(\"AUC LGBM: \", AUC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Aplicar la estandarización con StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicar la normalización con MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train_scaled)\n",
    "X_test_scaled = min_max_scaler.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-19 19:50:29,021]\u001b[0m A new study created in memory with name: no-name-881835c8-348c-4abf-85db-92c322f91542\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 19:50:57,930]\u001b[0m Trial 0 finished with value: 0.9003605207136085 and parameters: {'n_estimators': 62, 'learning_rate': 0.012167325242628762, 'algorithm': 'SAMME.R'}. Best is trial 0 with value: 0.9003605207136085.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 19:54:18,426]\u001b[0m Trial 1 finished with value: 0.9622434903937718 and parameters: {'n_estimators': 470, 'learning_rate': 0.01685188753976667, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 19:55:48,512]\u001b[0m Trial 2 finished with value: 0.9541504214067545 and parameters: {'n_estimators': 185, 'learning_rate': 0.012967299448727172, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 19:56:56,125]\u001b[0m Trial 3 finished with value: 0.8960126651265835 and parameters: {'n_estimators': 137, 'learning_rate': 0.005157494017167381, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:00:07,558]\u001b[0m Trial 4 finished with value: 0.9540860749469374 and parameters: {'n_estimators': 497, 'learning_rate': 0.01851150665987596, 'algorithm': 'SAMME'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:03:38,672]\u001b[0m Trial 5 finished with value: 0.952399755153096 and parameters: {'n_estimators': 487, 'learning_rate': 0.004189357069926789, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:06:58,596]\u001b[0m Trial 6 finished with value: 0.9619552178156091 and parameters: {'n_estimators': 468, 'learning_rate': 0.013642106253717166, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.9622434903937718.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:09:37,110]\u001b[0m Trial 7 finished with value: 0.9639145186563015 and parameters: {'n_estimators': 369, 'learning_rate': 0.0349060647656093, 'algorithm': 'SAMME.R'}. Best is trial 7 with value: 0.9639145186563015.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:11:19,738]\u001b[0m Trial 8 finished with value: 0.952409312474753 and parameters: {'n_estimators': 236, 'learning_rate': 0.009551912352673345, 'algorithm': 'SAMME.R'}. Best is trial 7 with value: 0.9639145186563015.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:14:09,077]\u001b[0m Trial 9 finished with value: 0.9209540790617782 and parameters: {'n_estimators': 490, 'learning_rate': 0.0019931738826937904, 'algorithm': 'SAMME'}. Best is trial 7 with value: 0.9639145186563015.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:16:12,508]\u001b[0m Trial 10 finished with value: 0.9545629859674236 and parameters: {'n_estimators': 353, 'learning_rate': 0.058573756808728304, 'algorithm': 'SAMME'}. Best is trial 7 with value: 0.9639145186563015.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:18:47,018]\u001b[0m Trial 11 finished with value: 0.963995438084256 and parameters: {'n_estimators': 357, 'learning_rate': 0.03932229628125123, 'algorithm': 'SAMME.R'}. Best is trial 11 with value: 0.963995438084256.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:21:18,177]\u001b[0m Trial 12 finished with value: 0.963985252872052 and parameters: {'n_estimators': 344, 'learning_rate': 0.056237075269423224, 'algorithm': 'SAMME.R'}. Best is trial 11 with value: 0.963995438084256.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:23:52,726]\u001b[0m Trial 13 finished with value: 0.9647429289493697 and parameters: {'n_estimators': 340, 'learning_rate': 0.09801544008842904, 'algorithm': 'SAMME.R'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:25:59,065]\u001b[0m Trial 14 finished with value: 0.9644921074709781 and parameters: {'n_estimators': 280, 'learning_rate': 0.09727630156757885, 'algorithm': 'SAMME.R'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:27:35,188]\u001b[0m Trial 15 finished with value: 0.9545855523767799 and parameters: {'n_estimators': 279, 'learning_rate': 0.06182569938377496, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:29:38,862]\u001b[0m Trial 16 finished with value: 0.9644920983932945 and parameters: {'n_estimators': 284, 'learning_rate': 0.09431659068523426, 'algorithm': 'SAMME.R'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:31:19,762]\u001b[0m Trial 17 finished with value: 0.9643207535937517 and parameters: {'n_estimators': 232, 'learning_rate': 0.09880554419426306, 'algorithm': 'SAMME.R'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:33:45,558]\u001b[0m Trial 18 finished with value: 0.9541343416223673 and parameters: {'n_estimators': 420, 'learning_rate': 0.02994354540770656, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n",
      "\u001b[32m[I 2023-06-19 20:36:03,399]\u001b[0m Trial 19 finished with value: 0.9621743433368659 and parameters: {'n_estimators': 310, 'learning_rate': 0.024027684049020347, 'algorithm': 'SAMME.R'}. Best is trial 13 with value: 0.9647429289493697.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor ROC AUC: 0.9647429289493697\n",
      "Mejores parámetros: {'n_estimators': 340, 'learning_rate': 0.09801544008842904, 'algorithm': 'SAMME.R'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir los parámetros a optimizar con Optuna\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R'])\n",
    "    }\n",
    "\n",
    "    # Crear el modelo de AdaBoost con los parámetros sugeridos por Optuna\n",
    "    model = AdaBoostClassifier(**params)\n",
    "\n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=strat_kfold, scoring='roc_auc')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "# Crear un estudio Optuna y optimizar los parámetros\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Imprimir los mejores parámetros y el valor de la métrica ROC AUC\n",
    "print('Mejor ROC AUC:', study.best_value)\n",
    "print('Mejores parámetros:', study.best_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ada = {'n_estimators': 340, \n",
    "            'learning_rate': 0.09801544008842904, \n",
    "            'algorithm': 'SAMME.R'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.09801544008842904, n_estimators=340)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.09801544008842904, n_estimators=340)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.09801544008842904, n_estimators=340)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Ada = AdaBoostClassifier(**best_ada)\n",
    "model_Ada.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = ROC_AUC(model_Ada, X_train_scaled, y_train)\n",
    "print(\"AUC ADA: \", AUC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Air_temperature_K</th>\n",
       "      <th>Process_temperature_K</th>\n",
       "      <th>Rotational_speed_rpm</th>\n",
       "      <th>Torque_Nm</th>\n",
       "      <th>Tool_wear_min</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>Type_H</th>\n",
       "      <th>Type_L</th>\n",
       "      <th>Type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50096</td>\n",
       "      <td>300.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1596</td>\n",
       "      <td>36.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20343</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1759</td>\n",
       "      <td>29.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49454</td>\n",
       "      <td>299.3</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1805</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53355</td>\n",
       "      <td>301.0</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1524</td>\n",
       "      <td>44.3</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24050</td>\n",
       "      <td>298.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  Air_temperature_K  Process_temperature_K  Rotational_speed_rpm  \\\n",
       "0       50096              300.6                  309.6                  1596   \n",
       "1       20343              302.6                  312.1                  1759   \n",
       "2       49454              299.3                  308.5                  1805   \n",
       "3       53355              301.0                  310.9                  1524   \n",
       "4       24050              298.0                  309.0                  1641   \n",
       "\n",
       "   Torque_Nm  Tool_wear_min  TWF  HDF  PWF  OSF  RNF  Type_H  Type_L  Type_M  \n",
       "0       36.1            140    0    0    0    0    0       0       1       0  \n",
       "1       29.1            200    0    0    0    0    0       0       0       1  \n",
       "2       26.5             25    0    0    0    0    0       0       1       0  \n",
       "3       44.3            197    0    0    0    0    0       0       1       0  \n",
       "4       35.4             34    0    0    0    0    0       0       0       1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Air_temperature_K</th>\n",
       "      <th>Process_temperature_K</th>\n",
       "      <th>Rotational_speed_rpm</th>\n",
       "      <th>Torque_Nm</th>\n",
       "      <th>Tool_wear_min</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>Type_H</th>\n",
       "      <th>Type_L</th>\n",
       "      <th>Type_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50896</td>\n",
       "      <td>302.3</td>\n",
       "      <td>311.5</td>\n",
       "      <td>1499</td>\n",
       "      <td>38.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53866</td>\n",
       "      <td>301.7</td>\n",
       "      <td>311.0</td>\n",
       "      <td>1713</td>\n",
       "      <td>28.8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50498</td>\n",
       "      <td>301.3</td>\n",
       "      <td>310.4</td>\n",
       "      <td>1525</td>\n",
       "      <td>37.7</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21232</td>\n",
       "      <td>300.1</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1479</td>\n",
       "      <td>47.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19751</td>\n",
       "      <td>303.4</td>\n",
       "      <td>312.3</td>\n",
       "      <td>1515</td>\n",
       "      <td>41.3</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  Air_temperature_K  Process_temperature_K  Rotational_speed_rpm  \\\n",
       "0       50896              302.3                  311.5                  1499   \n",
       "1       53866              301.7                  311.0                  1713   \n",
       "2       50498              301.3                  310.4                  1525   \n",
       "3       21232              300.1                  309.6                  1479   \n",
       "4       19751              303.4                  312.3                  1515   \n",
       "\n",
       "   Torque_Nm  Tool_wear_min  TWF  HDF  PWF  OSF  RNF  Type_H  Type_L  Type_M  \n",
       "0       38.0             60    0    0    0    0    0       0       1       0  \n",
       "1       28.8             17    0    0    0    0    0       0       1       0  \n",
       "2       37.7             96    0    0    0    0    0       0       1       0  \n",
       "3       47.6              5    0    0    0    0    0       0       0       1  \n",
       "4       41.3            114    0    0    0    0    0       0       0       1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Obtener las predicciones\n",
    "pred_lgbm = model_LGBM.predict_proba(X_train)[:,1]\n",
    "pred_xgb = model_XGB.predict_proba(X_train)[:,1]\n",
    "pred_cat = model_CAT.predict_proba(X_train_CAT.astype(str))[:,1]\n",
    "pred_hist = model_Hist.predict_proba(X_train)[:,1]\n",
    "pred_Ada = model_Ada.predict_proba(X_train_scaled)[:,1]\n",
    "\n",
    "X_train_meta_FE = pd.DataFrame({'lgbm': pred_lgbm, 'xgb': pred_xgb, 'cat': pred_cat, 'hist': pred_hist, 'ada': pred_Ada, 'target': y_train})\n",
    "\n",
    "pred_lgbm_test = model_LGBM.predict_proba(X_test)[:,1]\n",
    "pred_xgb_test = model_XGB.predict_proba(X_test)[:,1]\n",
    "pred_cat_test = model_CAT.predict_proba(X_test.astype(str))[:,1]\n",
    "pred_hist_test = model_Hist.predict_proba(X_test)[:,1]\n",
    "pred_Ada_test = model_Ada.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "X_test_meta_FE_TrainOri = pd.DataFrame({'lgbm': pred_lgbm_test, 'xgb': pred_xgb_test,'cat': pred_cat_test, 'hist': pred_hist_test, 'ada': pred_Ada_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90954 entries, 0 to 90953\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   Product_ID             90954 non-null  category\n",
      " 1   Type                   90954 non-null  category\n",
      " 2   Air_temperature_K      90954 non-null  float64 \n",
      " 3   Process_temperature_K  90954 non-null  float64 \n",
      " 4   Rotational_speed_rpm   90954 non-null  int64   \n",
      " 5   Torque_Nm              90954 non-null  float64 \n",
      " 6   Tool_wear_min          90954 non-null  int64   \n",
      " 7   TWF                    90954 non-null  int64   \n",
      " 8   HDF                    90954 non-null  int64   \n",
      " 9   PWF                    90954 non-null  int64   \n",
      " 10  OSF                    90954 non-null  int64   \n",
      " 11  RNF                    90954 non-null  int64   \n",
      "dtypes: category(2), float64(3), int64(7)\n",
      "memory usage: 7.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_CAT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las predicciones\n",
    "pred_lgbm = model_LGBM.predict_proba(X_train)[:,1]\n",
    "pred_xgb = model_XGB.predict_proba(X_train)[:,1]\n",
    "pred_cat = model_CAT.predict_proba(X_train_CAT)[:,1]\n",
    "\n",
    "\n",
    "X_train_meta_FE = pd.DataFrame({'lgbm': pred_lgbm, 'xgb': pred_xgb, 'cat': pred_cat, 'target': y_train})\n",
    "\n",
    "pred_lgbm_test = model_LGBM.predict_proba(X_test)[:,1]\n",
    "pred_xgb_test = model_XGB.predict_proba(X_test)[:,1]\n",
    "pred_cat_test = model_CAT.predict_proba(X_test_CAT)[:,1]\n",
    "\n",
    "X_test_meta_FE_TrainOri = pd.DataFrame({'lgbm': pred_lgbm_test, 'xgb': pred_xgb_test,'cat': pred_cat_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_meta_FE_TrainOri.to_csv('results/X_test_meta_TrainOri.csv', index=False)\n",
    "X_train_meta_FE.to_csv('results/X_train_meta_TrainOri.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tunning for meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_meta = X_test_meta_FE_TrainOri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_m = X_train_meta_FE['target']\n",
    "X_train_m = X_train_meta_FE.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:47<00:00, 12.95s/trial, best loss: -0.9992910628005761]\n",
      "Best:  {'colsample_bytree': 0.09081575196369268, 'learning_rate': 0.09832401564492325, 'max_depth': 16.0, 'min_child_samples': 21.0, 'n_estimators': 390.0, 'num_leaves': 21.0, 'reg_alpha': 0.36709509155020276, 'reg_lambda': 0.5389143108424922, 'subsample': 0.7446113262171848}\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import lightgbm as lgb\n",
    "# hp \n",
    "from hyperopt import hp, tpe, STATUS_OK, Trials, fmin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "space ={\n",
    "    'max_depth': hp.quniform('max_depth', 6, 18, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 100, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.01, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.4, 1.0),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 400, 10),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 100, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.15, 0.5),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.3, 1.0)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    model_LGBM_meta = lgb.LGBMClassifier(max_depth = int(space['max_depth']),\n",
    "                             learning_rate = space['learning_rate'],\n",
    "                             num_leaves = int(space['num_leaves']),\n",
    "                             n_estimators = int(space['n_estimators']),\n",
    "                             colsample_bytree = space['colsample_bytree'],\n",
    "                             subsample = space['subsample'],\n",
    "                             is_unbalance = True,\n",
    "                             min_child_samples = int(space['min_child_samples']),\n",
    "                             reg_alpha = space['reg_alpha'],\n",
    "                             reg_lambda = space['reg_lambda'])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    y_pred_proba = cross_val_predict(model_LGBM_meta, X_train_m, y_train_m, cv=cv, method='predict_proba')[:,1]\n",
    "    auc = roc_auc_score(y_train_m, y_pred_proba)\n",
    "    return {'loss': -auc, 'status': STATUS_OK}\n",
    "\n",
    "# Run the algorithm\n",
    "trials = Trials()\n",
    "best_LGBM_meta = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best_LGBM_meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best =  {'colsample_bytree': 0.09081575196369268,\n",
    "         'learning_rate': 0.09832401564492325,\n",
    "         'max_depth': 16, \n",
    "         'min_child_samples': 21, \n",
    "         'n_estimators': 390, \n",
    "         'num_leaves': 21, \n",
    "         'reg_alpha': 0.36709509155020276, \n",
    "         'reg_lambda': 0.5389143108424922, \n",
    "         'subsample': 0.7446113262171848} # best loss: -0.9992910628005761\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_meta_LGBM =  {'colsample_bytree': 0.22071462239650944, \n",
    "                'learning_rate': 0.0071184882183990906, \n",
    "                'max_depth': 12, \n",
    "                'min_child_samples': 91, \n",
    "                'n_estimators': 180, \n",
    "                'num_leaves': 20, \n",
    "                'reg_alpha': 0.34357926147986606, \n",
    "                'reg_lambda': 0.9332514748078644, \n",
    "                'subsample': 0.9562001151634876} # 0.988\n",
    "\n",
    "best_LGBM_meta = {'colsample_bytree': 0.026181323096692063, \n",
    "                  'learning_rate': 0.04207644660879477, \n",
    "                  'max_depth': 6, \n",
    "                  'min_child_samples': 26, \n",
    "                  'n_estimators': 190, \n",
    "                  'num_leaves': 21, \n",
    "                  'reg_alpha': 0.4910393820375527, \n",
    "                  'reg_lambda': 0.6246168616161446, \n",
    "                  'subsample': 0.41742010255980644} # 0.9923355097281873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC META LGBM tunned:  0.9894180616922632\n"
     ]
    }
   ],
   "source": [
    "model_meta_LGBM = lgb.LGBMClassifier(**Best)\n",
    "\n",
    "AUC_META_LGBM_tunned = ROC_AUC(model_meta_LGBM, X_train_m, y_train_m)\n",
    "print(\"AUC META LGBM tunned: \", AUC_META_LGBM_tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.09081575196369268,\n",
       "               learning_rate=0.09832401564492325, max_depth=16,\n",
       "               min_child_samples=21, n_estimators=390, num_leaves=21,\n",
       "               reg_alpha=0.36709509155020276, reg_lambda=0.5389143108424922,\n",
       "               subsample=0.7446113262171848)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.09081575196369268,\n",
       "               learning_rate=0.09832401564492325, max_depth=16,\n",
       "               min_child_samples=21, n_estimators=390, num_leaves=21,\n",
       "               reg_alpha=0.36709509155020276, reg_lambda=0.5389143108424922,\n",
       "               subsample=0.7446113262171848)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.09081575196369268,\n",
       "               learning_rate=0.09832401564492325, max_depth=16,\n",
       "               min_child_samples=21, n_estimators=390, num_leaves=21,\n",
       "               reg_alpha=0.36709509155020276, reg_lambda=0.5389143108424922,\n",
       "               subsample=0.7446113262171848)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_meta_LGBM.fit(X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_meta_LGBM.predict_proba(X_test_meta)[:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m cv \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39m# Realizar la validación cruzada\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m n_scores \u001b[39m=\u001b[39m cross_val_score(stacking_model, X, y, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, error_score\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mraise\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     58\u001b[0m \u001b[39m# Reportar el rendimiento del modelo\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (np\u001b[39m.\u001b[39mmean(n_scores), np\u001b[39m.\u001b[39mstd(n_scores)))\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Crear el transformador personalizado\n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_copy[col] = X_copy[col].astype('category')\n",
    "        return X_copy\n",
    "\n",
    "# Asignar los datos de entrada\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Crear un conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# Columnas que necesitan ser transformadas para model_CAT\n",
    "categorical_features = ['Product_ID', 'Type']\n",
    "categorical_transformer = CategoricalTransformer(categorical_features)\n",
    "\n",
    "# Incluir el transformador en un Pipeline con model_CAT\n",
    "model_CAT = CatBoostClassifier()\n",
    "model_CAT = Pipeline(steps=[('categorical_transformer', categorical_transformer),\n",
    "                            ('classifier', model_CAT)])\n",
    "\n",
    "# Ahora, model_CAT incluirá el preprocesamiento necesario y puedes usarlo en tu modelo de stacking como antes\n",
    "base_models = [\n",
    "    ('LGBM', model_LGBM),\n",
    "    ('XGB', model_XGB),\n",
    "    ('CatBoost', model_CAT)  \n",
    "]\n",
    "\n",
    "# Definir el metamodelo\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Definir el modelo de stacking\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Definir el procedimiento de validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Realizar la validación cruzada\n",
    "n_scores = cross_val_score(stacking_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Reportar el rendimiento del modelo\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Supongamos que ya tienes tres modelos entrenados: model1, model2, model_CAT\n",
    "# model1 y model2 están entrenados en X1 y model_CAT está entrenado en X2\n",
    "\n",
    "# Crear un clasificador de votación\n",
    "voting_model = VotingClassifier(estimators=[('model1', model_LGBM), ('model2', model_XGB), ('model_CAT', model_CAT)], voting='soft')\n",
    "\n",
    "# Entrenar el clasificador de votación\n",
    "# Nota: Esto asume que tienes correspondencias uno a uno entre las filas de X1, X2, y y\n",
    "# es decir, la i-ésima fila de X1, la i-ésima fila de X2 y el i-ésimo elemento de y todos corresponden a la misma observación\n",
    "voting_model.fit([X_train, X_train_CAT], y_train)\n",
    "\n",
    "# Ahora puedes hacer predicciones con el modelo de votación\n",
    "y_pred = voting_model.predict([X_test, X_test_CAT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146429, 14)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146429, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_CAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146429 entries, 0 to 146428\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype   \n",
      "---  ------                 --------------   -----   \n",
      " 0   Product_ID             146429 non-null  category\n",
      " 1   Type                   146429 non-null  category\n",
      " 2   Air_temperature_K      146429 non-null  float64 \n",
      " 3   Process_temperature_K  146429 non-null  float64 \n",
      " 4   Rotational_speed_rpm   146429 non-null  int64   \n",
      " 5   Torque_Nm              146429 non-null  float64 \n",
      " 6   Tool_wear_min          146429 non-null  int64   \n",
      " 7   Machine_failure        146429 non-null  int64   \n",
      " 8   TWF                    146429 non-null  int64   \n",
      " 9   HDF                    146429 non-null  int64   \n",
      " 10  PWF                    146429 non-null  int64   \n",
      " 11  OSF                    146429 non-null  int64   \n",
      " 12  RNF                    146429 non-null  int64   \n",
      "dtypes: category(2), float64(3), int64(8)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_CAT.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146429 entries, 0 to 146428\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Product_ID             146429 non-null  int64  \n",
      " 1   Air_temperature_K      146429 non-null  float64\n",
      " 2   Process_temperature_K  146429 non-null  float64\n",
      " 3   Rotational_speed_rpm   146429 non-null  int64  \n",
      " 4   Torque_Nm              146429 non-null  float64\n",
      " 5   Tool_wear_min          146429 non-null  int64  \n",
      " 6   TWF                    146429 non-null  int64  \n",
      " 7   HDF                    146429 non-null  int64  \n",
      " 8   PWF                    146429 non-null  int64  \n",
      " 9   OSF                    146429 non-null  int64  \n",
      " 10  RNF                    146429 non-null  int64  \n",
      " 11  Type_H                 146429 non-null  int64  \n",
      " 12  Type_L                 146429 non-null  int64  \n",
      " 13  Type_M                 146429 non-null  int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 15.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90954 entries, 0 to 90953\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Product_ID             90954 non-null  int64  \n",
      " 1   Air_temperature_K      90954 non-null  float64\n",
      " 2   Process_temperature_K  90954 non-null  float64\n",
      " 3   Rotational_speed_rpm   90954 non-null  int64  \n",
      " 4   Torque_Nm              90954 non-null  float64\n",
      " 5   Tool_wear_min          90954 non-null  int64  \n",
      " 6   TWF                    90954 non-null  int64  \n",
      " 7   HDF                    90954 non-null  int64  \n",
      " 8   PWF                    90954 non-null  int64  \n",
      " 9   OSF                    90954 non-null  int64  \n",
      " 10  RNF                    90954 non-null  int64  \n",
      " 11  Type_H                 90954 non-null  int64  \n",
      " 12  Type_L                 90954 non-null  int64  \n",
      " 13  Type_M                 90954 non-null  int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 9.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Supongamos que ya tienes tres modelos entrenados: model1, model2, model_CAT\n",
    "# model1 y model2 están entrenados en X1 y model_CAT está entrenado en X2\n",
    "\n",
    "# Crear un clasificador de votación\n",
    "voting_model = VotingClassifier(estimators=[('model1', model_LGBM), ('model2', model_XGB), ('model_CAT', model_CAT)], voting='soft')\n",
    "\n",
    "# Predecir con los modelos base y preparar los datos para el metamodelo\n",
    "X_meta_train = pd.DataFrame({\n",
    "    'model1': model_LGBM.predict_proba(X_train)[:,1],\n",
    "    'model2': model_XGB.predict_proba(X_train)[:,1],\n",
    "    'model_CAT': model_CAT.predict_proba(X_train_CAT)[:,1]\n",
    "})\n",
    "\n",
    "X_meta_test = pd.DataFrame({\n",
    "    'model1': model_LGBM.predict_proba(X_test)[:,1],\n",
    "    'model2': model_XGB.predict_proba(X_test)[:,1],\n",
    "    'model_CAT': model_CAT.predict_proba(X_test_CAT)[:,1]\n",
    "})\n",
    "\n",
    "# Entrenar el metamodelo\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_meta_train, y_train)\n",
    "\n",
    "# Ahora puedes hacer predicciones con el metamodelo\n",
    "y_pred = meta_model.predict(X_meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Primero, obtén las probabilidades de la clase positiva con el método `predict_proba`\n",
    "y_pred_proba = meta_model.predict_proba(X_meta_train)[:, 1]\n",
    "\n",
    "# Ahora calcula la métrica ROC AUC\n",
    "roc_auc = roc_auc_score(y_train, y_pred_proba)\n",
    "\n",
    "print('ROC AUC: %.3f' % roc_auc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_meta_LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 5 and input n_features is 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_analysis \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_proba(X_train)[:,\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py:997\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X, raw_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, start_iteration\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, num_iteration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    995\u001b[0m                   pred_leaf\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, pred_contrib\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    996\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    998\u001b[0m     \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objective) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (raw_score \u001b[39mor\u001b[39;00m pred_leaf \u001b[39mor\u001b[39;00m pred_contrib):\n\u001b[0;32m    999\u001b[0m         _log_warning(\u001b[39m\"\u001b[39m\u001b[39mCannot compute class probabilities or labels \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1000\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mdue to the usage of customized objective function.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1001\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mReturning raw scores instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jose\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\sklearn.py:800\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    798\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features \u001b[39m!=\u001b[39m n_features:\n\u001b[1;32m--> 800\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of features of the model must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    801\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch the input. Model n_features_ is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput n_features is \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    803\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mpredict(X, raw_score\u001b[39m=\u001b[39mraw_score, start_iteration\u001b[39m=\u001b[39mstart_iteration, num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[0;32m    804\u001b[0m                              pred_leaf\u001b[39m=\u001b[39mpred_leaf, pred_contrib\u001b[39m=\u001b[39mpred_contrib, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 5 and input n_features is 14"
     ]
    }
   ],
   "source": [
    "y_pred_analysis = model.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_analysis = X_train.copy()\n",
    "X_train_analysis['Machine_failure'] = y_train\n",
    "X_train_analysis['Machine_failure_pred'] = y_pred_analysis\n",
    "X_train_analysis['Error'] = X_train_analysis['Machine_failure'] - X_train_analysis['Machine_failure_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_analysis.to_csv('data/X_train_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_submission = pd.read_csv('input/test.csv') # Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission to a file\n",
    "# Rounded pred increases the score\n",
    "submission = pd.DataFrame({'id': X_test_submission['id'], 'Machine failure': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
